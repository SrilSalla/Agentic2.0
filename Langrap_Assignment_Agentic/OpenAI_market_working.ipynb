{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67525fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing query: 'Tell me the latest news'\n",
      "Result: Final Validated Answer: Web Crawler fetched data for: Tell me the latest news\n",
      "\n",
      "Processing query: 'Show me the internal report'\n",
      "Result: Final Validated Answer: RAG Retrieved Data for: Show me the internal report\n",
      "\n",
      "Processing query: 'Explain quantum computing'\n",
      "Result: Final Validated Answer: [LLM Response to] Explain quantum computing\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "# Define the state using Pydantic\n",
    "class AgentState(BaseModel):\n",
    "    input: Optional[str] = None\n",
    "    messages: List[Union[HumanMessage, AIMessage]] = Field(default_factory=list)\n",
    "    step: int = 0\n",
    "    validation_status: Optional[str] = None\n",
    "    intermediate_result: Optional[str] = None\n",
    "    output: Optional[str] = None\n",
    "\n",
    "# Simple pass-through nodes\n",
    "def supervisor_node(state: AgentState):\n",
    "    return state\n",
    "\n",
    "def router_node(state: AgentState):\n",
    "    return state\n",
    "\n",
    "# Processing nodes\n",
    "def llm_node(state: AgentState):\n",
    "    query = state.input or \"\"\n",
    "    response = f\"[LLM Response to] {query}\"\n",
    "    return {\n",
    "        \"intermediate_result\": response,\n",
    "        \"messages\": state.messages + [AIMessage(content=response)]\n",
    "    }\n",
    "\n",
    "def rag_node(state: AgentState):\n",
    "    query = state.input or \"\"\n",
    "    response = f\"RAG Retrieved Data for: {query}\"\n",
    "    return {\n",
    "        \"intermediate_result\": response,\n",
    "        \"messages\": state.messages + [AIMessage(content=response)]\n",
    "    }\n",
    "\n",
    "def web_crawler_node(state: AgentState):\n",
    "    query = state.input or \"\"\n",
    "    response = f\"Web Crawler fetched data for: {query}\"\n",
    "    return {\n",
    "        \"intermediate_result\": response,\n",
    "        \"messages\": state.messages + [AIMessage(content=response)]\n",
    "    }\n",
    "\n",
    "def validation_node(state: AgentState):\n",
    "    content = state.intermediate_result or \"\"\n",
    "    if \"fail\" in content.lower():\n",
    "        return {\"validation_status\": \"fail\"}\n",
    "    return {\"validation_status\": \"pass\"}\n",
    "\n",
    "def final_output_node(state: AgentState):\n",
    "    return {\"output\": f\"Final Validated Answer: {state.intermediate_result}\"}\n",
    "\n",
    "# Build the workflow graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Add all nodes\n",
    "graph.add_node(\"supervisor_node\", supervisor_node)\n",
    "graph.add_node(\"router_node\", router_node)\n",
    "graph.add_node(\"llm_node\", llm_node)\n",
    "graph.add_node(\"rag_node\", rag_node)\n",
    "graph.add_node(\"web_crawler_node\", web_crawler_node)\n",
    "graph.add_node(\"validation_node\", validation_node)\n",
    "graph.add_node(\"final_output_node\", final_output_node)\n",
    "\n",
    "# Set entry point\n",
    "graph.set_entry_point(\"supervisor_node\")\n",
    "\n",
    "# First edge (supervisor to router)\n",
    "graph.add_edge(\"supervisor_node\", \"router_node\")\n",
    "\n",
    "# Conditional routing from router\n",
    "graph.add_conditional_edges(\n",
    "    \"router_node\",\n",
    "    lambda state: (\n",
    "        \"web_crawler_node\" if (\"latest\" in (state.input or \"\").lower() or \"current\" in (state.input or \"\").lower())\n",
    "        else \"rag_node\" if (\"report\" in (state.input or \"\").lower() or \"internal\" in (state.input or \"\").lower())\n",
    "        else \"llm_node\"\n",
    "    ),\n",
    "    {\n",
    "        \"web_crawler_node\": \"web_crawler_node\",\n",
    "        \"rag_node\": \"rag_node\",\n",
    "        \"llm_node\": \"llm_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Processing paths\n",
    "graph.add_edge(\"llm_node\", \"validation_node\")\n",
    "graph.add_edge(\"rag_node\", \"validation_node\")\n",
    "graph.add_edge(\"web_crawler_node\", \"validation_node\")\n",
    "\n",
    "# Validation conditional edges\n",
    "graph.add_conditional_edges(\n",
    "    \"validation_node\",\n",
    "    lambda state: state.validation_status,\n",
    "    {\n",
    "        \"pass\": \"final_output_node\",\n",
    "        \"fail\": \"supervisor_node\"  # Loop back on failure\n",
    "    }\n",
    ")\n",
    "\n",
    "# Set finish point\n",
    "graph.set_finish_point(\"final_output_node\")\n",
    "\n",
    "# Compile the workflow\n",
    "workflow = graph.compile()\n",
    "\n",
    "# Test the workflow\n",
    "test_cases = [\n",
    "    \"Tell me the latest news\",  # -> web crawler\n",
    "    \"Show me the internal report\",  # -> RAG\n",
    "    \"Explain quantum computing\",  # -> LLM\n",
    "]\n",
    "\n",
    "for user_query in test_cases:\n",
    "    print(f\"\\nProcessing query: '{user_query}'\")\n",
    "    initial_state = AgentState(\n",
    "        input=user_query,\n",
    "        messages=[HumanMessage(content=user_query)]\n",
    "    )\n",
    "    result = workflow.invoke(initial_state)\n",
    "    print(\"Result:\", result[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
